[tool.poetry]
name = "domain-embedding-finetuner"
version = "0.1.0"
description = "Lightweight pipeline to parse a domain-specific PDF, generate training data, fine-tune a Llama-3.2 (1B) SLM, and compare embedding performance against the base model."
authors = ["Caitlin Arnspiger <caitthedev@gmail.com>"]
license = "MIT"
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.10"
pdfplumber = "^0.11.6"
pyyaml = "^6.0.2"
peft = "^0.15.2"
openai = "^1.79.0"
tenacity = "^9.1.2"
python-dotenv = "^1.1.0"
bitsandbytes = "^0.45.5"
transformers = "^4.51.3"
accelerate = "^1.7.0"
llama-cpp-python = "^0.3.9"
datasets = "^3.6.0"
faiss-cpu = "^1.11.0"


[tool.poetry.group.dev.dependencies]
jupyter = "^1.1.1"
black = "^25.1.0"
isort = "^6.0.1"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
